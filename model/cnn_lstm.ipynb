{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 132)\n",
      "(1500, 132)\n",
      "X shape: (100, 30, 132)\n",
      "y shape: (100,)\n"
     ]
    }
   ],
   "source": [
    "# prompt: We got 2 files correct_keypoints_normalized.npy and wrong one. Reshape the data to 3d arrays (samples, 30,132) and labels it\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def reshape_and_label_data(correct_file, wrong_file):\n",
    "  \"\"\"\n",
    "  Reshapes data from .npy files into 3D arrays and assigns labels.\n",
    "\n",
    "  Args:\n",
    "    correct_file: Path to the .npy file containing correctly labeled data.\n",
    "    wrong_file: Path to the .npy file containing incorrectly labeled data.\n",
    "\n",
    "  Returns:\n",
    "    A tuple containing:\n",
    "      - X: A NumPy array with shape (samples, 30, 132) containing the reshaped data.\n",
    "      - y: A NumPy array with shape (samples,) containing the labels (0 for incorrect, 1 for correct).\n",
    "  \"\"\"\n",
    "  correct_data = np.load(correct_file)\n",
    "  wrong_data = np.load(wrong_file)\n",
    "  print(correct_data.shape)\n",
    "  print(wrong_data.shape)\n",
    "  # Reshape the data\n",
    "  correct_data_reshaped = correct_data.reshape(-1, 30, 132)\n",
    "  wrong_data_reshaped = wrong_data.reshape(-1, 30, 132)\n",
    "\n",
    "  # Combine data and create labels\n",
    "  X = np.concatenate((correct_data_reshaped, wrong_data_reshaped), axis=0)\n",
    "  y = np.concatenate((np.ones(correct_data_reshaped.shape[0]), np.zeros(wrong_data_reshaped.shape[0])), axis=0)\n",
    "  \n",
    "  return X, y\n",
    "\n",
    "# Example usage:\n",
    "correct_file = r'C:\\VS_Workspace\\push-up-detection\\output_data\\processed_key\\correct_keypoints\\correct_keypoints_normalized_keypoints.npy'\n",
    "wrong_file = r'C:\\VS_Workspace\\push-up-detection\\output_data\\processed_key\\wrong_keypoints\\wrong_keypoints_normalized_keypoints.npy' #replace with your wrong file path\n",
    "X, y = reshape_and_label_data(correct_file, wrong_file)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (80, 30, 132)\n",
      "y_train shape: (80,)\n",
      "X_test shape: (20, 30, 132)\n",
      "y_test shape: (20,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X and y are defined as in the previous code\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # 80% train, 20% test\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 6s 154ms/step - loss: 0.6669 - accuracy: 0.6375 - val_loss: 0.7251 - val_accuracy: 0.4000\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.5990 - accuracy: 0.7500 - val_loss: 0.7056 - val_accuracy: 0.4000\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.5364 - accuracy: 0.8250 - val_loss: 0.7140 - val_accuracy: 0.4000\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4575 - accuracy: 0.8375 - val_loss: 0.6792 - val_accuracy: 0.6500\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4350 - accuracy: 0.8875 - val_loss: 0.6567 - val_accuracy: 0.7000\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3408 - accuracy: 0.8750 - val_loss: 0.6395 - val_accuracy: 0.6500\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3633 - accuracy: 0.8750 - val_loss: 0.6480 - val_accuracy: 0.6500\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3600 - accuracy: 0.8500 - val_loss: 0.6265 - val_accuracy: 0.6500\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.2927 - accuracy: 0.8625 - val_loss: 0.6186 - val_accuracy: 0.6500\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.2849 - accuracy: 0.9125 - val_loss: 0.7121 - val_accuracy: 0.4500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7121 - accuracy: 0.4500\n",
      "Test Loss: 0.7121\n",
      "Test Accuracy: 0.4500\n"
     ]
    }
   ],
   "source": [
    "# prompt: build cnn-lstm model with sequential 30 frames \n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization\n",
    "\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are defined as in the previous code\n",
    "\n",
    "# Define the CNN-LSTM model\n",
    "model = Sequential()\n",
    "\n",
    "# CNN layers\n",
    "model.add(Conv1D(filters=12, kernel_size=3, activation='relu', input_shape=(30, 132)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "# model.add(Dropout(0.25))  # Add dropout for regularization\n",
    "\n",
    "model.add(Conv1D(filters=24, kernel_size=3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "# LSTM layer\n",
    "model.add(LSTM(units=64))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "# Dense layers\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))  # Output layer for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "# model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=12, validation_data=(X_test, y_test)) # Adjust epochs and batch_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
